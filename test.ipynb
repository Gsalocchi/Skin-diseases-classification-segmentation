{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "275f3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import get_device\n",
    "from model_task_3 import train_model\n",
    "from data_processing import get_loaders, class_cols\n",
    "from model_task_3 import create_model, train_model\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9531a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 train_loss=0.2618 val_loss=2.9973 train_acc=0.0497 val_acc=0.0592\n",
      "  ✓ New best val_acc=0.0592, model saved to best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 train_loss=0.1565 val_loss=3.4493 train_acc=0.0707 val_acc=0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 train_loss=0.1337 val_loss=2.5317 train_acc=0.0996 val_acc=0.1184\n",
      "  ✓ New best val_acc=0.1184, model saved to best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 train_loss=0.1256 val_loss=2.7537 train_acc=0.1017 val_acc=0.0732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 train_loss=0.1192 val_loss=2.4248 train_acc=0.1074 val_acc=0.1337\n",
      "  ✓ New best val_acc=0.1337, model saved to best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 train_loss=0.1151 val_loss=2.7210 train_acc=0.1385 val_acc=0.0878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 train_loss=0.1172 val_loss=3.2072 train_acc=0.1261 val_acc=0.0958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 train_loss=0.1115 val_loss=2.9691 train_acc=0.1698 val_acc=0.0725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 train_loss=0.1059 val_loss=2.4817 train_acc=0.1507 val_acc=0.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 train_loss=0.1035 val_loss=1.6955 train_acc=0.1554 val_acc=0.3886\n",
      "  ✓ New best val_acc=0.3886, model saved to best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 train_loss=0.0997 val_loss=2.0075 train_acc=0.2334 val_acc=0.3440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 train_loss=0.0964 val_loss=2.7324 train_acc=0.2300 val_acc=0.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 train_loss=0.0860 val_loss=2.3145 train_acc=0.2338 val_acc=0.1650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 train_loss=0.0882 val_loss=2.1882 train_acc=0.1571 val_acc=0.1956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 train_loss=0.0815 val_loss=2.0767 train_acc=0.2162 val_acc=0.2974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 train_loss=0.0752 val_loss=2.2914 train_acc=0.2676 val_acc=0.2735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 train_loss=0.0696 val_loss=1.9433 train_acc=0.2788 val_acc=0.2954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 train_loss=0.0610 val_loss=2.1399 train_acc=0.2750 val_acc=0.2861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     12\u001b[39m class_counts = [\u001b[38;5;28mint\u001b[39m(train_df[c].sum()) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m class_cols_order]\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#base_model = create_model(num_classes=num_classes, model_name=\"vit_base_patch16_384\")\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#ckpt = torch.load(\"best_model.pth\", map_location=device)\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#base_model.load_state_dict(ckpt[\"model_state\"])\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m model, history2 = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_counts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#model=base_model,          \u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbest_model.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code_Projects/CV 2025/model_task_3.py:177\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(train_loader, val_loader, num_classes, model_name, epochs, lr, weight_decay, device, class_counts, save_path, model)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m    168\u001b[39m     train_loss, train_acc = train_one_epoch(\n\u001b[32m    169\u001b[39m         model,\n\u001b[32m    170\u001b[39m         train_loader,\n\u001b[32m   (...)\u001b[39m\u001b[32m    175\u001b[39m         total_epochs=epochs,\n\u001b[32m    176\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     val_loss, val_acc = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m     scheduler.step()\n\u001b[32m    181\u001b[39m     history[\u001b[33m\"\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m\"\u001b[39m].append(train_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cv_project/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code_Projects/CV 2025/model_task_3.py:114\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(model, loader, device)\u001b[39m\n\u001b[32m    111\u001b[39m loss = criterion(logits, labels)\n\u001b[32m    113\u001b[39m bs = images.size(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * bs\n\u001b[32m    115\u001b[39m preds = logits.argmax(\u001b[32m1\u001b[39m)\n\u001b[32m    116\u001b[39m total_correct += (preds == labels).sum().item()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "device = get_device()\n",
    "\n",
    "train_loader, val_loader, train_df, val_df = get_loaders(\n",
    "    image_size=(384, 384),\n",
    "    num_workers=0,\n",
    ")\n",
    "class_cols_order = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
    "num_classes = len(class_cols_order)\n",
    "model = create_model(num_classes=num_classes, model_name=\"vit_base_patch16_384\")\n",
    "\n",
    "\n",
    "class_counts = [int(train_df[c].sum()) for c in class_cols_order]\n",
    "\n",
    "#base_model = create_model(num_classes=num_classes, model_name=\"vit_base_patch16_384\")\n",
    "#ckpt = torch.load(\"best_model.pth\", map_location=device)\n",
    "#base_model.load_state_dict(ckpt[\"model_state\"])\n",
    "\n",
    "\n",
    "model, history2 = train_model(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_classes=num_classes,\n",
    "    device=device,\n",
    "    epochs=15,                 \n",
    "    class_counts=class_counts,\n",
    "    #model=base_model,          \n",
    "    save_path=\"best_model.pth\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d81244b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: \"'data/Task_3/ISIC2018_Task3_Training_GroundTruth.csv' # Gian\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata_processing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TASK_3_TEST_LABELS_DIR\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Try to get loaders and request the test CSV explicitly (module-level constant used as default)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m loaders = \u001b[43mget_loaders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m384\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_csv_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTASK_3_TEST_LABELS_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# unpack safely depending on what get_loaders returned\u001b[39;00m\n\u001b[32m     13\u001b[39m test_loader = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code_Projects/CV 2025/data_processing.py:163\u001b[39m, in \u001b[36mget_loaders\u001b[39m\u001b[34m(csv_path, images_dir, val_csv_path, val_images_dir, test_csv_path, test_images_dir, image_size, batch_size, num_workers)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_loaders\u001b[39m(\n\u001b[32m    153\u001b[39m     csv_path: \u001b[38;5;28mstr\u001b[39m = TASK_3_TRAIN_LABELS_DIR,\n\u001b[32m    154\u001b[39m     images_dir: \u001b[38;5;28mstr\u001b[39m = TASK_3_TRAIN_IMAGES_DIR,\n\u001b[32m   (...)\u001b[39m\u001b[32m    161\u001b[39m     num_workers: \u001b[38;5;28mint\u001b[39m = NUM_WORKERS,\n\u001b[32m    162\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     dfs = \u001b[43mbuild_dfs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_csv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_images_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_csv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images_dir\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dfs) == \u001b[32m3\u001b[39m:\n\u001b[32m    167\u001b[39m         train_df, val_df, test_df = dfs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code_Projects/CV 2025/data_processing.py:54\u001b[39m, in \u001b[36mbuild_dfs\u001b[39m\u001b[34m(csv_path, images_dir, val_csv_path, val_images_dir, test_csv_path, test_images_dir)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Build train/val (and optional test) dataframes.\u001b[39;00m\n\u001b[32m     46\u001b[39m \n\u001b[32m     47\u001b[39m \u001b[33;03mBehavior:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m \u001b[33;03m- If `test_csv_path` is provided, read it and return the test DF as well.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# read train CSV\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m train_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# turn one-hot into single label\u001b[39;00m\n\u001b[32m     56\u001b[39m train_df[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m] = train_df[class_cols].values.argmax(axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cv_project/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cv_project/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cv_project/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cv_project/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cv_project/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: \"'data/Task_3/ISIC2018_Task3_Training_GroundTruth.csv' # Gian\""
     ]
    }
   ],
   "source": [
    "# Evaluate on test set (if available)\n",
    "# This cell will request loaders including the test set and compute test loss/accuracy\n",
    "from data_processing import TASK_3_TEST_LABELS_DIR\n",
    "\n",
    "# Try to get loaders and request the test CSV explicitly (module-level constant used as default)\n",
    "loaders = get_loaders(\n",
    "    image_size=(384, 384),\n",
    "    num_workers=0,\n",
    "    test_csv_path=TASK_3_TEST_LABELS_DIR,\n",
    ")\n",
    "\n",
    "# unpack safely depending on what get_loaders returned\n",
    "test_loader = None\n",
    "if isinstance(loaders, tuple) and len(loaders) == 6:\n",
    "    train_loader, val_loader, test_loader, train_df, val_df, test_df = loaders\n",
    "elif isinstance(loaders, tuple) and len(loaders) == 4:\n",
    "    train_loader, val_loader, train_df, val_df = loaders\n",
    "    test_loader = None\n",
    "else:\n",
    "    # unexpected shape\n",
    "    test_loader = None\n",
    "\n",
    "if test_loader is None:\n",
    "    print(\"No test loader available. Provide a test CSV/images or adjust get_loaders to return a test loader.\")\n",
    "else:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "\n",
    "    device = get_device()\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += xb.size(0)\n",
    "\n",
    "    test_loss = running_loss / total if total > 0 else 0.0\n",
    "    test_acc = correct / total if total > 0 else 0.0\n",
    "    print(f\"Test samples: {total}\")\n",
    "    print(f\"Test loss: {test_loss:.4f}\")\n",
    "    print(f\"Test accuracy: {test_acc:.4%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2851de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for views, labels in train_loader:\n",
    "    # views is a list/tuple of tensors: [weak_batch, strong_batch]\n",
    "    weak_imgs, strong_imgs = views[0].to(device), views[1].to(device)\n",
    "    labels = labels.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
